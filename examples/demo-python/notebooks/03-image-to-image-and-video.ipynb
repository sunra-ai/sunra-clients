{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Image-to-Image and Image-to-Video with Sunra AI\n",
        "\n",
        "This notebook explores working with input images to create transformations and videos.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- Image-to-image transformations\n",
        "- Image-to-video generation\n",
        "- Working with image URLs\n",
        "- Upload and preprocessing techniques\n",
        "- Video generation parameters\n",
        "- Combining multiple modalities\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup\n",
        "\n",
        "Let's set up our environment:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sunra_client\n",
        "import requests\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import time\n",
        "import getpass\n",
        "from IPython.display import Video, HTML\n",
        "\n",
        "# Set up API key if not already configured\n",
        "if 'SUNRA_KEY' not in os.environ:\n",
        "    api_key = getpass.getpass(\"Enter your Sunra API key: \")\n",
        "    os.environ['SUNRA_KEY'] = api_key\n",
        "\n",
        "# Configure the client\n",
        "sunra_client.config(credentials=os.environ['SUNRA_KEY'])\n",
        "print(\"✓ Sunra client configured successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "Let's create helper functions for working with images and videos:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_image(image_url, title=\"Generated Image\", size=(10, 10)):\n",
        "    \"\"\"Download and display an image from a URL\"\"\"\n",
        "    try:\n",
        "        response = requests.get(image_url)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        \n",
        "        plt.figure(figsize=size)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(title)\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"Image size: {img.size}\")\n",
        "        print(f\"Image format: {img.format}\")\n",
        "        return img\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error displaying image: {e}\")\n",
        "        print(f\"You can view the image directly at: {image_url}\")\n",
        "        return None\n",
        "\n",
        "def display_video(video_url, title=\"Generated Video\"):\n",
        "    \"\"\"Display a video from a URL\"\"\"\n",
        "    try:\n",
        "        print(f\"Video URL: {video_url}\")\n",
        "        print(f\"Title: {title}\")\n",
        "        \n",
        "        # Create HTML video element\n",
        "        video_html = f\"\"\"\n",
        "        <video width=\"640\" height=\"480\" controls>\n",
        "            <source src=\"{video_url}\" type=\"video/mp4\">\n",
        "            Your browser does not support the video tag.\n",
        "        </video>\n",
        "        \"\"\"\n",
        "        \n",
        "        display(HTML(video_html))\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error displaying video: {e}\")\n",
        "        print(f\"You can view the video directly at: {video_url}\")\n",
        "\n",
        "def generate_image_to_image(prompt, input_image_url, strength=0.8, show_result=True):\n",
        "    \"\"\"Generate an image-to-image transformation\"\"\"\n",
        "    \n",
        "    print(f\"Generating image-to-image with prompt: '{prompt}'\")\n",
        "    print(f\"Input image: {input_image_url}\")\n",
        "    print(\"Please wait...\")\n",
        "    \n",
        "    try:\n",
        "        result = sunra_client.subscribe(\n",
        "            \"black-forest-labs/flux-kontext-pro/image-to-image\",\n",
        "            arguments={\n",
        "                \"prompt\": prompt,\n",
        "                \"image\": input_image_url,\n",
        "                \"strength\": strength,\n",
        "                \"prompt_enhancer\": False,\n",
        "                \"seed\": 0,\n",
        "                \"aspect_ratio\": \"1:1\",\n",
        "                \"output_format\": \"jpeg\",\n",
        "                \"safety_tolerance\": 6\n",
        "            },\n",
        "            with_logs=True,\n",
        "            on_enqueue=lambda req_id: print(f\"✓ Request enqueued: {req_id}\"),\n",
        "            on_queue_update=lambda status: print(f\"Status: {status}\"),\n",
        "        )\n",
        "        \n",
        "        if result.get('images'):\n",
        "            image_url = result['images'][0]['url']\n",
        "            print(f\"✓ Image transformation completed!\")\n",
        "            print(f\"Result URL: {image_url}\")\n",
        "            \n",
        "            if show_result:\n",
        "                display_image(image_url, f\"Transformed: {prompt}\")\n",
        "            \n",
        "            return result\n",
        "        else:\n",
        "            print(\"No image generated\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error generating image: {e}\")\n",
        "        return None\n",
        "\n",
        "def generate_image_to_video(prompt, input_image_url, duration=5, guidance_scale=0.5, show_result=True):\n",
        "    \"\"\"Generate a video from an image\"\"\"\n",
        "    \n",
        "    print(f\"Generating video with prompt: '{prompt}'\")\n",
        "    print(f\"Input image: {input_image_url}\")\n",
        "    print(f\"Duration: {duration} seconds\")\n",
        "    print(\"Please wait... (this may take longer than image generation)\")\n",
        "    \n",
        "    try:\n",
        "        result = sunra_client.subscribe(\n",
        "            \"kling/kling-v2-master/image-to-video\",\n",
        "            arguments={\n",
        "                \"prompt\": prompt,\n",
        "                \"negative_prompt\": \"\",\n",
        "                \"guidance_scale\": guidance_scale,\n",
        "                \"aspect_ratio\": \"16:9\",\n",
        "                \"duration\": duration,\n",
        "                \"start_image\": input_image_url\n",
        "            },\n",
        "            with_logs=True,\n",
        "            on_enqueue=lambda req_id: print(f\"✓ Request enqueued: {req_id}\"),\n",
        "            on_queue_update=lambda status: print(f\"Status: {status}\"),\n",
        "        )\n",
        "        \n",
        "        if result.get('videos'):\n",
        "            video_url = result['videos'][0]['url']\n",
        "            print(f\"✓ Video generation completed!\")\n",
        "            print(f\"Video URL: {video_url}\")\n",
        "            \n",
        "            if show_result:\n",
        "                display_video(video_url, f\"Video: {prompt}\")\n",
        "            \n",
        "            return result\n",
        "        else:\n",
        "            print(\"No video generated\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error generating video: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"Helper functions ready!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Create a Base Image\n",
        "\n",
        "First, let's create a base image that we can transform:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a base image to work with\n",
        "base_prompt = \"a simple portrait of a person in a garden\"\n",
        "\n",
        "try:\n",
        "    result = sunra_client.subscribe(\n",
        "        \"black-forest-labs/flux-kontext-pro/text-to-image\",\n",
        "        arguments={\n",
        "            \"prompt\": base_prompt,\n",
        "            \"prompt_enhancer\": False,\n",
        "            \"seed\": 42,\n",
        "            \"aspect_ratio\": \"1:1\",\n",
        "            \"output_format\": \"jpeg\",\n",
        "            \"safety_tolerance\": 6\n",
        "        },\n",
        "        with_logs=True,\n",
        "        on_enqueue=lambda req_id: print(f\"✓ Request enqueued: {req_id}\"),\n",
        "        on_queue_update=lambda status: print(f\"Status: {status}\"),\n",
        "    )\n",
        "    \n",
        "    if result.get('images'):\n",
        "        base_image_url = result['images'][0]['url']\n",
        "        print(f\"✓ Base image generated!\")\n",
        "        print(f\"Base image URL: {base_image_url}\")\n",
        "        \n",
        "        display_image(base_image_url, \"Base Image: \" + base_prompt)\n",
        "    else:\n",
        "        print(\"No base image generated\")\n",
        "        base_image_url = None\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error generating base image: {e}\")\n",
        "    base_image_url = None\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Image-to-Image Transformation\n",
        "\n",
        "Now let's transform our base image with different prompts. If you don't have a base image, we'll use a sample image:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use our generated image or a sample image\n",
        "if base_image_url:\n",
        "    input_image = base_image_url\n",
        "else:\n",
        "    # Use a sample image from the original demo\n",
        "    input_image = \"https://assets.sunra.ai/uploads/1748811753168-05ceab0d.png\"\n",
        "    print(\"Using sample image for transformation\")\n",
        "    display_image(input_image, \"Sample Input Image\")\n",
        "\n",
        "# Transform the image with different prompts\n",
        "transformations = [\n",
        "    \"convert to a watercolor painting style\",\n",
        "    \"make it look like a renaissance painting\",\n",
        "    \"transform into a cyberpunk style with neon colors\",\n",
        "    \"convert to a pencil sketch drawing\"\n",
        "]\n",
        "\n",
        "for i, transform_prompt in enumerate(transformations, 1):\n",
        "    print(f\"\\n=== Transformation {i}: {transform_prompt} ===\")\n",
        "    result = generate_image_to_image(transform_prompt, input_image, strength=0.8)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Image-to-Video Generation\n",
        "\n",
        "Now let's create a video from our image. This is more computationally intensive and may take longer:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a video from our image\n",
        "video_prompt = \"A cute hamster lies leisurely on a lifebuoy, wearing fashionable sunglasses, and drifts with the gentle waves on the shimmering sea surface. The hamster reclines comfortably, enjoying a peaceful and pleasant time. Cartoon style, the camera follows the subject moving, with a heartwarming and high picture quality.\"\n",
        "\n",
        "# Use the sample image from the original demo for consistency\n",
        "sample_image = \"https://assets.sunra.ai/uploads/1748811753168-05ceab0d.png\"\n",
        "\n",
        "print(\"Generating video from image...\")\n",
        "print(\"This may take several minutes, please be patient...\")\n",
        "\n",
        "video_result = generate_image_to_video(\n",
        "    video_prompt, \n",
        "    sample_image, \n",
        "    duration=5, \n",
        "    guidance_scale=0.5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Understanding Strength Parameter\n",
        "\n",
        "The `strength` parameter in image-to-image generation controls how much the AI should change the input image:\n",
        "\n",
        "- **0.0**: Minimal changes (output very similar to input)\n",
        "- **0.5**: Moderate changes (balanced between input and prompt)\n",
        "- **1.0**: Maximum changes (prompt has strongest influence)\n",
        "\n",
        "Let's see this in action:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different strength values\n",
        "test_image = \"https://assets.sunra.ai/uploads/1748811753168-05ceab0d.png\"\n",
        "test_prompt = \"transform into a magical fairy tale illustration\"\n",
        "\n",
        "strength_values = [0.3, 0.5, 0.8, 1.0]\n",
        "\n",
        "print(\"Comparing different strength values:\")\n",
        "print(\"Original image:\")\n",
        "display_image(test_image, \"Original Image\")\n",
        "\n",
        "for strength in strength_values:\n",
        "    print(f\"\\n=== Strength: {strength} ===\")\n",
        "    result = generate_image_to_image(test_prompt, test_image, strength=strength)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Video Generation Parameters\n",
        "\n",
        "Let's explore different video generation parameters:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Different video generation approaches\n",
        "video_test_image = \"https://assets.sunra.ai/uploads/1748811753168-05ceab0d.png\"\n",
        "\n",
        "video_experiments = [\n",
        "    {\n",
        "        \"prompt\": \"gentle waves moving in slow motion\",\n",
        "        \"duration\": 3,\n",
        "        \"guidance_scale\": 0.3\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"floating peacefully with subtle camera movement\",\n",
        "        \"duration\": 5,\n",
        "        \"guidance_scale\": 0.5\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"dramatic ocean scene with dynamic camera angles\",\n",
        "        \"duration\": 5,\n",
        "        \"guidance_scale\": 0.8\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"Generating videos with different parameters...\")\n",
        "print(\"Note: Each video may take several minutes to generate\")\n",
        "\n",
        "for i, experiment in enumerate(video_experiments, 1):\n",
        "    print(f\"\\n=== Video Experiment {i} ===\")\n",
        "    print(f\"Prompt: {experiment['prompt']}\")\n",
        "    print(f\"Duration: {experiment['duration']}s\")\n",
        "    print(f\"Guidance Scale: {experiment['guidance_scale']}\")\n",
        "    \n",
        "    # Note: In practice, you might want to run only one at a time due to processing time\n",
        "    # Uncomment the line below to generate the video\n",
        "    # result = generate_image_to_video(experiment['prompt'], video_test_image, \n",
        "    #                                 duration=experiment['duration'], \n",
        "    #                                 guidance_scale=experiment['guidance_scale'])\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Working with Your Own Images\n",
        "\n",
        "If you have your own images you'd like to use, you'll need to upload them to a public URL first. Here are some options:\n",
        "\n",
        "### Option 1: Using a Cloud Storage Service\n",
        "- Google Drive (make sure to use direct download links)\n",
        "- Dropbox\n",
        "- Amazon S3\n",
        "- GitHub (for public repositories)\n",
        "\n",
        "### Option 2: Using Image Hosting Services\n",
        "- Imgur\n",
        "- Cloudinary\n",
        "- Any image hosting service that provides direct URLs\n",
        "\n",
        "### Important Notes:\n",
        "- The URL must be publicly accessible\n",
        "- The URL should point directly to the image file (not a webpage)\n",
        "- Supported formats: JPEG, PNG, WebP\n",
        "- Recommended size: Up to 2048x2048 pixels\n",
        "\n",
        "Here's how to test if your image URL works:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_image_url(image_url):\n",
        "    \"\"\"Test if an image URL is accessible and valid\"\"\"\n",
        "    try:\n",
        "        print(f\"Testing image URL: {image_url}\")\n",
        "        response = requests.get(image_url)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            print(f\"✓ Image accessible!\")\n",
        "            print(f\"  Format: {img.format}\")\n",
        "            print(f\"  Size: {img.size}\")\n",
        "            print(f\"  Mode: {img.mode}\")\n",
        "            \n",
        "            # Display the image\n",
        "            display_image(image_url, \"Your Image\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"❌ HTTP Error: {response.status_code}\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        return False\n",
        "\n",
        "# Test with a sample image\n",
        "sample_url = \"https://assets.sunra.ai/uploads/1748811753168-05ceab0d.png\"\n",
        "test_image_url(sample_url)\n",
        "\n",
        "# To test your own image, uncomment and modify the line below:\n",
        "# test_image_url(\"YOUR_IMAGE_URL_HERE\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary and Best Practices\n",
        "\n",
        "### Key Takeaways:\n",
        "\n",
        "1. **Image-to-Image**: Great for style transfers and modifications\n",
        "2. **Image-to-Video**: Creates dynamic content from static images\n",
        "3. **Strength Parameter**: Controls how much the AI changes the input\n",
        "4. **Video Parameters**: Duration and guidance scale affect the output\n",
        "5. **Input Requirements**: Images must be publicly accessible URLs\n",
        "\n",
        "### Best Practices:\n",
        "\n",
        "- **Test URLs First**: Always verify your image URLs work\n",
        "- **Choose Appropriate Strength**: 0.5-0.8 usually works well for most transformations\n",
        "- **Be Patient with Videos**: Video generation takes significantly longer than images\n",
        "- **Clear Prompts**: Describe the desired motion or transformation clearly\n",
        "- **Reasonable Durations**: 3-5 seconds is usually sufficient and faster to generate\n",
        "\n",
        "### Common Use Cases:\n",
        "\n",
        "- **Style Transfer**: Transform photos into different art styles\n",
        "- **Animation**: Bring static images to life with movement\n",
        "- **Concept Exploration**: Test different visual approaches with the same base image\n",
        "- **Creative Projects**: Generate unique variations of existing artwork\n",
        "\n",
        "### Parameters Reference:\n",
        "\n",
        "#### Image-to-Image:\n",
        "- `prompt`: Description of desired transformation\n",
        "- `image`: URL of input image\n",
        "- `strength`: 0.0-1.0, controls transformation intensity\n",
        "- `aspect_ratio`: Output dimensions\n",
        "- `output_format`: \"jpeg\", \"png\", \"webp\"\n",
        "\n",
        "#### Image-to-Video:\n",
        "- `prompt`: Description of desired motion/scene\n",
        "- `start_image`: URL of input image\n",
        "- `duration`: Video length in seconds (3-10)\n",
        "- `guidance_scale`: 0.1-1.0, controls prompt adherence\n",
        "- `aspect_ratio`: Video dimensions\n",
        "- `negative_prompt`: What to avoid in the video\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Continue to the next notebook: **04-speech-to-text.ipynb** to learn about audio processing with Sunra AI!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
